{
  "version": "1.0",  // Optional: Version of the template format
  "agent_id": "unique-agent-id",  // Required: Unique identifier for the agent
  "name": "Display Name",  // Required: Name shown in UI
  "description": "Brief description of the agent.",  // Required: Description for UI
  "tags": ["Example", "Research"],  // Optional: Tags for categorization
  "priority": 10,  // Optional: Lower numbers appear higher in lists
  "personality": [  // Required: System prompt broken into lines/paragraphs
    "Personality trait 1",
    "Personality trait 2"
  ],
  "nodes": [  // Required: List of node types used by the agent
    "llm.openai",  // Example: Specify the LLM node provider
    "search"       // Example: Include necessary tool nodes
  ],
  "node_configurations": {  // Required: Configuration for specific nodes
    "llm.openai": {  // Key matches the node type from the "nodes" list
      "model": "YOUR_CHOSEN_MODEL",  // Required: Specify the model ID
      "temperature": 0.7,  // Optional: Controls randomness (0=deterministic, >0=more random). Range varies by provider.
      "max_tokens": 4096,  // Optional: Max tokens for the response.
      "top_p": 0.9,  // Optional: Nucleus sampling (0-1). Consider only top P% probability mass. Use temperature OR topP.
      "top_k": 50,  // Optional: Consider only the top K most likely tokens.
      "frequency_penalty": 0.2,  // Optional: Penalizes frequently used tokens (0=no penalty). Range varies.
      "presence_penalty": 0.1,  // Optional: Penalizes tokens already present in prompt/response (0=no penalty). Range varies.
      "stop_sequences": ["\nUser:"],  // Optional: Sequences that stop generation.
      "seed": 12345,  // Optional: Integer for deterministic results (if supported).
      "use_custom_api_key": false  // Optional: If true, requires user to provide API key in settings.
    },
    "search": {  // Example: Configuration for a tool node (if needed)
      "max_results": 5  // Optional: Max results to return from the search
    }
  },
  "chat_settings": {  // Required: Settings for the chat interface
    "history_policy": "lastN",  // Optional: 'none', 'lastN', 'all' (default: 'lastN')
    "history_length": 20,  // Optional: Number of messages if policy is 'lastN' (default: 50)
    "initial_messages": [  // Optional: Messages shown when chat starts
      "Hello! How can I help?"
    ],
    "chat_prompts": [  // Optional: Suggested prompts shown in UI
      "What can you do?"
    ]
  },
  "options": {  // Optional: Additional agent-level options
    "max_steps": 10  // Optional: Max tool execution steps per turn
  }
}
